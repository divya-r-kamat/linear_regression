{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.stats as stats\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    boston = load_boston()\n",
    "    print (boston.DESCR)\n",
    "    X = boston[\"data\"]\n",
    "    Y = boston[\"target\"]\n",
    "    names = boston[\"feature_names\"]\n",
    "    return X,Y,names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "def scale_data(X):\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(X,Y):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "def regression_predictor(model,x_test,y_test):\n",
    "    y_pred = model.predict(x_test)\n",
    "    mse = mean_squared_error(y_test,y_pred)\n",
    "    mae = mean_absolute_error(y_test,y_pred)\n",
    "    r2 = r2_score(y_test,y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    adj_r_squared = 1 - (1-r2)*(len(y_test)-1)/(len(y_test)- x_test.shape[1]- 1)\n",
    "    stats = pd.DataFrame({'rmse':rmse,'mse':mse,'mae':mae,'r2':r2,'adj_r_squared':adj_r_squared},index=['name'])\n",
    "    return model,y_pred,stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "def linear_regression(X_train,y_train):\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(X_train,y_train)\n",
    "    return regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_residuals(y_test,y_pred,name=\"Residual Plot\"):\n",
    "    residuals = y_test - y_pred\n",
    "    plt.scatter(y_test,residuals)\n",
    "    plt.title(name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "def cross_validation_regressor(model,x_train,y_train):\n",
    "    kf = KFold(n_splits=10, random_state=7)\n",
    "    score = cross_val_score(model,x_train,y_train,cv=kf)\n",
    "    return score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "def lasso(x_train,x_test,y_train,y_test,alpha):\n",
    "    lass = Lasso(alpha=alpha,random_state=7)\n",
    "    model = lass.fit(x_train,y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    mse = mean_squared_error(y_test,y_pred)\n",
    "    mae = mean_absolute_error(y_test,y_pred)\n",
    "    r2=model.score(x_test,y_test)\n",
    "    rmse = np.sqrt(mse)\n",
    "    val = cross_validation_regressor(lass,x_train,y_train)\n",
    "    adj_r_squared = 1 - (1-r2)*(len(y_test)-1)/(len(y_test)- x_test.shape[1]- 1)\n",
    "    stats = pd.DataFrame({'cross_validation':val,\n",
    "                        'rmse':rmse,'mse':mse,'mae':mae,'r2':(model.score(x_test,y_test)),'adj_r_squared':adj_r_squared},index=['name'])\n",
    "\n",
    "    #stats = pd.DataFrame({'rmse':rmse,'mse':mse,'mae':mae,'r2':(model.score(x_test,y_test)),'adj_r_squared':adj_r_squared},index=['name'])\n",
    "                                \n",
    "    return model,y_pred,stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "def ridge(x_train,x_test,y_train,y_test,alpha):\n",
    "    rid = Ridge(alpha=alpha,random_state=7,fit_intercept=True)\n",
    "    model = rid.fit(x_train,y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    mse = mean_squared_error(y_test,y_pred)\n",
    "    mae = mean_absolute_error(y_test,y_pred)\n",
    "    r2=model.score(x_test,y_test)\n",
    "    rmse = np.sqrt(mse)\n",
    "    val = cross_validation_regressor(rid,x_train,y_train)\n",
    "    adj_r_squared = 1 - (1-r2)*(len(y_test)-1)/(len(y_test)- x_test.shape[1]- 1)\n",
    "    stats = pd.DataFrame({'cross_validation':val,\n",
    "                        'rmse':rmse,'mse':mse,'mae':mae,'r2':(model.score(x_test,y_test)),'adj_r_squared':adj_r_squared},index=['name'])\n",
    "    return model,y_pred,stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "def elasticnet(x_train,x_test,y_train,y_test,alpha):\n",
    "    rid = ElasticNet(alpha=alpha,random_state=7,fit_intercept=True)\n",
    "    model = rid.fit(x_train,y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    mse = mean_squared_error(y_test,y_pred)\n",
    "    mae = mean_absolute_error(y_test,y_pred)\n",
    "    r2=model.score(x_test,y_test)\n",
    "    rmse = np.sqrt(mse)\n",
    "    #val = cross_validation_regressor(rid,x_train,y_train)\n",
    "    adj_r_squared = 1 - (1-r2)*(len(y_test)-1)/(len(y_test)- x_test.shape[1]- 1)\n",
    "    stats = pd.DataFrame({'rmse':rmse,'mse':mse,'mae':mae,'r2':model.score(x_test,y_test),'adj_r_squared':adj_r_squared},index=['name'])\n",
    "    return model,y_pred,stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def generate_regression_values(model, X, y):\n",
    "    params = np.append(model.intercept_, model.coef_)\n",
    "    predictions = model.predict(X)\n",
    "    newX = pd.DataFrame({\"Constant\": np.ones(len(X))}).join(pd.DataFrame(X))\n",
    "    MSE = (sum((y - predictions) ** 2)) / (len(newX) - len(newX.columns))\n",
    "    MSE = mean_squared_error(y,predictions)\n",
    "\n",
    "    # Note if you don't want to use a DataFrame replace the two lines above with\n",
    "    # newX = np.append(np.ones((len(X),1)), X, axis=1)\n",
    "    # MSE = (sum((y-predictions)**2))/(len(newX)-len(newX[0]))\n",
    "\n",
    "    var_b = MSE * (np.linalg.inv(np.dot(newX.T, newX)).diagonal())\n",
    "    sd_b = np.sqrt(var_b)\n",
    "    ts_b = params / sd_b\n",
    "\n",
    "    p_values = [2 * (1 - stats.t.cdf(np.abs(i), (len(newX) - 1))) for i in ts_b]\n",
    "\n",
    "    sd_b = np.round(sd_b, 3)\n",
    "    ts_b = np.round(ts_b, 3)\n",
    "    p_values = np.round(p_values, 3)\n",
    "    params = np.round(params, 4)\n",
    "\n",
    "    myDF3 = pd.DataFrame()\n",
    "    myDF3[\"Coefficients\"], myDF3[\"Standard Errors\"], myDF3[\"t values\"], myDF3[\n",
    "        \"Probabilites\"\n",
    "    ] = [params,sd_b, ts_b, p_values]\n",
    "    print(myDF3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston House Prices dataset\n",
      "===========================\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X,Y,names = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X = scale_data(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model Used:\n",
      " LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "\n",
      " Model Statistics:\n",
      "       adj_r_squared       mae        mse        r2      rmse\n",
      "name       0.702558  3.151288  20.747143  0.725852  4.554903\n",
      "    Coefficients  Standard Errors  t values  Probabilites\n",
      "0        22.4647            0.367    61.165         0.000\n",
      "1        -1.0998            0.412    -2.669         0.008\n",
      "2         0.8806            0.512     1.721         0.087\n",
      "3         0.4017            0.820     0.490         0.625\n",
      "4         0.8221            0.430     1.912         0.058\n",
      "5        -1.8779            0.743    -2.528         0.012\n",
      "6         2.7330            0.545     5.010         0.000\n",
      "7        -0.3596            0.675    -0.533         0.595\n",
      "8        -2.9940            0.738    -4.059         0.000\n",
      "9         2.0399            0.981     2.078         0.039\n",
      "10       -1.3811            1.120    -1.233         0.219\n",
      "11       -2.0113            0.548    -3.671         0.000\n",
      "12        1.0867            0.419     2.591         0.010\n",
      "13       -3.9129            0.750    -5.220         0.000\n"
     ]
    }
   ],
   "source": [
    "model = linear_regression(X_train,y_train)\n",
    "#val = cross_validation_regressor(model,X_train,y_train)\n",
    "model,y_pred,status = regression_predictor(model, X_test, y_test)\n",
    "#print (\"Linear model: \", pretty_print_linear(model.coef_, names, sort = True))\n",
    "\n",
    "print(\"\\n Model Used:\\n\", model)\n",
    "print(\"\\n Model Statistics:\\n\",status)\n",
    "\n",
    "generate_regression_values(model, X_test, y_test)\n",
    "plot_residuals(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model Used:\n",
      " Lasso(alpha=0.3, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=7,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False)\n",
      "\n",
      " Model Statistics:\n",
      "       adj_r_squared  cross_validation       mae       mse        r2      rmse\n",
      "name       0.663402          0.683638  3.302667  23.47833  0.689762  4.845444\n",
      "    Coefficients  Standard Errors  t values  Probabilites\n",
      "0        22.5148            0.391    57.626         0.000\n",
      "1        -0.2896            0.438    -0.661         0.510\n",
      "2         0.0000            0.544     0.000         1.000\n",
      "3        -0.0000            0.872    -0.000         1.000\n",
      "4         0.7363            0.457     1.610         0.109\n",
      "5        -0.4249            0.790    -0.538         0.591\n",
      "6         2.8562            0.580     4.922         0.000\n",
      "7        -0.0000            0.718    -0.000         1.000\n",
      "8        -0.9108            0.785    -1.161         0.247\n",
      "9         0.0000            1.044     0.000         1.000\n",
      "10       -0.0000            1.192    -0.000         1.000\n",
      "11       -1.6121            0.583    -2.766         0.006\n",
      "12        0.8066            0.446     1.808         0.072\n",
      "13       -4.0121            0.797    -5.031         0.000\n"
     ]
    }
   ],
   "source": [
    "model,y_pred,status = lasso(X_train,X_test,y_train,y_test,alpha=0.3)\n",
    "\n",
    "print(\"\\n Model Used:\\n\", model)\n",
    "print(\"\\n Model Statistics:\\n\",status)\n",
    "\n",
    "generate_regression_values(model, X_test, y_test)\n",
    "plot_residuals(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model Used:\n",
      " Ridge(alpha=0.3, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=7, solver='auto', tol=0.001)\n",
      "\n",
      " Model Statistics:\n",
      "       adj_r_squared  cross_validation       mae        mse        r2      rmse\n",
      "name       0.702442          0.692328  3.150524  20.755217  0.725745  4.555789\n",
      "    Coefficients  Standard Errors  t values  Probabilites\n",
      "0        22.4650            0.367    61.154         0.000\n",
      "1        -1.0949            0.412    -2.657         0.009\n",
      "2         0.8736            0.512     1.707         0.090\n",
      "3         0.3927            0.820     0.479         0.633\n",
      "4         0.8239            0.430     1.916         0.057\n",
      "5        -1.8665            0.743    -2.512         0.013\n",
      "6         2.7353            0.546     5.013         0.000\n",
      "7        -0.3605            0.675    -0.534         0.594\n",
      "8        -2.9812            0.738    -4.041         0.000\n",
      "9         2.0139            0.982     2.052         0.042\n",
      "10       -1.3587            1.120    -1.213         0.227\n",
      "11       -2.0077            0.548    -3.664         0.000\n",
      "12        1.0858            0.420     2.588         0.011\n",
      "13       -3.9083            0.750    -5.212         0.000\n"
     ]
    }
   ],
   "source": [
    "model,y_pred,status = ridge(X_train,X_test,y_train,y_test,alpha=0.3)\n",
    "\n",
    "print(\"\\n Model Used:\\n\", model)\n",
    "print(\"\\n Model Statistics:\\n\",status)\n",
    "\n",
    "generate_regression_values(model, X_test, y_test)\n",
    "plot_residuals(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model Used:\n",
      " ElasticNet(alpha=0.3, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "      random_state=7, selection='cyclic', tol=0.0001, warm_start=False)\n",
      "\n",
      " Model Statistics:\n",
      "       adj_r_squared       mae        mse        r2      rmse\n",
      "name       0.668218  3.260832  23.142398  0.694201  4.810655\n",
      "    Coefficients  Standard Errors  t values  Probabilites\n",
      "0        22.5284            0.388    58.077         0.000\n",
      "1        -0.5055            0.435    -1.162         0.247\n",
      "2         0.1951            0.541     0.361         0.719\n",
      "3        -0.0376            0.866    -0.043         0.965\n",
      "4         0.8515            0.454     1.875         0.063\n",
      "5        -0.7029            0.785    -0.896         0.372\n",
      "6         2.7987            0.576     4.858         0.000\n",
      "7        -0.1623            0.713    -0.228         0.820\n",
      "8        -1.1416            0.779    -1.466         0.145\n",
      "9         0.0000            1.037     0.000         1.000\n",
      "10       -0.0547            1.183    -0.046         0.963\n",
      "11       -1.5756            0.579    -2.723         0.007\n",
      "12        0.8504            0.443     1.920         0.057\n",
      "13       -3.3402            0.792    -4.219         0.000\n"
     ]
    }
   ],
   "source": [
    "model,y_pred,status = elasticnet(X_train,X_test,y_train,y_test,alpha=0.3)\n",
    "\n",
    "print(\"\\n Model Used:\\n\", model)\n",
    "print(\"\\n Model Statistics:\\n\",status)\n",
    "\n",
    "generate_regression_values(model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
